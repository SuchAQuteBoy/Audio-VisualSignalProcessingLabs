<center>
<div>
<img src="https://raw.githubusercontent.com/SuchAQuteBoy/Pictures/master/HIT1.png" height="80"/>
</div>
<div>
<font size="10">实验报告</font>
</div>
<div>
<table border="0">
<tr>
<td align="left">题目</td>
<td align="left">基本语音识别匹配</td>
</tr>
<tr>
<td align="left">专业</td>
<td align="left">计算机科学与技术</td>
</tr>
<tr>
<td align="left">学号</td>
<td align="left">1160300329</td>
</tr>
<tr>
<td align="left">班级</td>
<td align="left">1603107</td>
</tr>
<tr>
<td align="left">学生</td>
<td align="left">黄海</td>
</tr>
<tr>
<td align="left">指导教师</td>
<td align="left">郑铁然</td>
</tr>
<tr>
<td align="left">实验地点</td>
<td align="left">G709</td>
</tr>
<tr>
<td align="left">实验日期</td>
<td align="left">11.11</td>
</tr>
</table>
</div>
<div>
<font size="5">计算机科学与技术学院</font>
</div>
</center>

<div STYLE="page-break-after: always;"></div>

<center>

# 一、语音文件的处理

</center>

## 1.1 样本安排

我们在进行后续实验之前需要进行一系列的处理 包括对声音的采样和特征向量的提取

对声音文件的处理主要是提取特征 这里我们使用了HTK工具包来对语音信息进行MFCC特征提取 来获得语音特征 为之后的DTW作准备

我一共采集了共110个数据 其中10个为模版数据 另外的100个为对应测试集 全部数据均分成了10个短词 来进行处理

<center>

![](https://raw.githubusercontent.com/SuchAQuteBoy/Pictures/master/Audio-VisualSignalProcessing/Lab3/1.png)

</center>

## 1.2 MFCC提取

wav文件的原始数据对于算法是无法直接使用的 我使用了HTK的工具包 使用Hcopy来对文件进行了特征提取

HTK工具包原本是在Windows环境下设计使用的 但是由于本人的开发机为Mac 所以遇到了以下问题 并逐个解决

- **HTK工具包只能在Windows下正常使用**<br/>我下载了HTK工具包的所有源代码 在Mac环境下进行全编译 生成相应的可执行程序 兼容性得到了解决
- **WAV文件格式在两者环境下不统一**<br/>Windows下的wav文件头部 在RIFF后存在换行标志 然后是数据 但是在Unix系统下没有换行标志 并且HTK工具无法识别 只能在Windows下进行采集 然后进行处理

在得到mfc文件之后 通过HTK工具下的Hlist来进一步处理 得到可以直接读取的数据文件

<center>

![](https://raw.githubusercontent.com/SuchAQuteBoy/Pictures/master/Audio-VisualSignalProcessing/Lab3/2.png)

</center>

<center>

# 二、DTW的具体实现

</center>

## 2.1 数据的存储和读取

对于文件中的数据 我们重用参数来节省内存空间

<center>

![](https://raw.githubusercontent.com/SuchAQuteBoy/Pictures/master/Audio-VisualSignalProcessing/Lab3/3.png)

</center>

之后在主要数据结构中使用list来进行存储和运算 进一步节省资源 减少不必要的计算内容

<center>

![](https://raw.githubusercontent.com/SuchAQuteBoy/Pictures/master/Audio-VisualSignalProcessing/Lab3/4.png)

</center>

在进行dtw数据比对时可以直接传入模板和测试集 进行测试

## 2.2 DTW算法的实现

DTW算法也被叫做动态时间规整算法 通过比对两个语音特征的时序特征进行偏移 来得到最小的偏移距离 同时也完成了短词的语音匹配

我们有以下的定义:

$$
Data_1 = {a_1, a_2, a_3, \cdots a_n} \\

Data_2 = {b_1, b_2, b_3, \cdots b_n}
$$

这两者分别代表了语音数据特征 对于这两个特征 都各自保证按照时序来进行排列 也间接的阻止了之后时序偏移时后一帧先出现的情况(较晚的帧绝不可能在较早出现)

这里 我们需要考虑的是更加一般的情况 即$Data_1$ $Data_2$长度不同 我们可以一般的将两者映射到二维空间的两个方向上 并将时间的零点对齐

这时空间中的每个点相当于两个帧的交汇点 从$(0, 0)$到$(m, n)$代表了两个语音之间的对应关系 我们可以找到这样一条路径 使得路径的两端贯穿映射关系 并且距离最短 这里我们对每个对应点都有一个对应的偏移长度 即横纵对应数据的差 即距离

对于每一个不靠近轴的点 它的值取决于三个点 假设这个点为$(i,j)$ 那么这个点的偏移最短总距离可以表达成:

$$
TotalDistence(i, j) = Min(Distence(i-1, j-1), Distence(i, j-1), Distence(i-1, j)) + Distence(i, j)
$$

其中$Distence$为这一点的静态距离 为直接的横纵对应数据的差

这便是DTW的动态规划算法 最终的$TotalDistence(m, n)$为最后的结果

<center>

![](https://raw.githubusercontent.com/SuchAQuteBoy/Pictures/master/Audio-VisualSignalProcessing/Lab3/5.png)

</center>

# 三、 结果

</center>

上述的DTW算法为经典DTW算法 采取了动态规划的思想 总体时间复杂度为$O(n^2)$ 依旧过高 并不能在较短的时间内得出答案

通过粗略计算 整体的解决时间在 **三个小时** 左右 所以并没有进行完全运行 只对各部分进行了正确性测试

最后的正确率为 **0.76** 较低

</center>

# 四、 总结

</center>

## 4.1 请总结本次实验的收获

这次的实验对与我来说很有挑战 并不是在算法 而是在HTK文间编译和WAV文件的处理上 在查阅了相关的文档之后 明白了文件格式的差异以及运行解析方式 对不同操作平台的差异了解更多

对于DTW算法 了解了简单语音数据处理的内容 对HMM算法充满好奇

## 4.2 请给出对本次实验内容的建议

希望能够统一实验在Linux或者是类Unix环境下进行 能够更好的加深理解